{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Random Forest: Best Accuracy <span style=\"font-weight: bold\">(</span>CV<span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9925</span> | Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9900</span> | Best Params = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'max_depth'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'min_samples_leaf'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_samples_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'n_estimators'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Random Forest: Best Accuracy \u001b[1m(\u001b[0mCV\u001b[1m)\u001b[0m = \u001b[1;36m0.9925\u001b[0m | Test Accuracy = \u001b[1;36m0.9900\u001b[0m | Best Params = \u001b[1m{\u001b[0m\u001b[32m'max_depth'\u001b[0m: \u001b[3;35mNone\u001b[0m, \n",
       "\u001b[32m'min_samples_leaf'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'min_samples_split'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 Random Forest Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 Random Forest Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.99\u001b[0m        \u001b[1;36m58\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.99\u001b[0m        \u001b[1;36m42\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.99\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logistic Regression: Best Accuracy <span style=\"font-weight: bold\">(</span>CV<span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9700</span> | Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9700</span> | Best Params = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'C'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'solver'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lbfgs'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Logistic Regression: Best Accuracy \u001b[1m(\u001b[0mCV\u001b[1m)\u001b[0m = \u001b[1;36m0.9700\u001b[0m | Test Accuracy = \u001b[1;36m0.9700\u001b[0m | Best Params = \u001b[1m{\u001b[0m\u001b[32m'C'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'solver'\u001b[0m: \n",
       "\u001b[32m'lbfgs'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 Logistic Regression Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 Logistic Regression Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.97\u001b[0m        \u001b[1;36m58\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.96\u001b[0m        \u001b[1;36m42\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.97\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.97\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.97\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Gradient Boosting: Best Accuracy <span style=\"font-weight: bold\">(</span>CV<span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9975</span> | Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9900</span> | Best Params = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'learning_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'max_depth'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'n_estimators'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Gradient Boosting: Best Accuracy \u001b[1m(\u001b[0mCV\u001b[1m)\u001b[0m = \u001b[1;36m0.9975\u001b[0m | Test Accuracy = \u001b[1;36m0.9900\u001b[0m | Best Params = \u001b[1m{\u001b[0m\u001b[32m'learning_rate'\u001b[0m: \u001b[1;36m0.01\u001b[0m, \n",
       "\u001b[32m'max_depth'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'n_estimators'\u001b[0m: \u001b[1;36m50\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 Gradient Boosting Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 Gradient Boosting Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.99\u001b[0m        \u001b[1;36m58\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.99\u001b[0m        \u001b[1;36m42\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.99\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m      \u001b[1;36m0.99\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Vector Machine: Best Accuracy <span style=\"font-weight: bold\">(</span>CV<span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9600</span> | Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9800</span> | Best Params = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'C'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'kernel'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'rbf'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Support Vector Machine: Best Accuracy \u001b[1m(\u001b[0mCV\u001b[1m)\u001b[0m = \u001b[1;36m0.9600\u001b[0m | Test Accuracy = \u001b[1;36m0.9800\u001b[0m | Best Params = \u001b[1m{\u001b[0m\u001b[32m'C'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'kernel'\u001b[0m: \n",
       "\u001b[32m'rbf'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 Support Vector Machine Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 Support Vector Machine Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m        \u001b[1;36m58\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m        \u001b[1;36m42\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.98\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m      \u001b[1;36m0.98\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">K-Nearest Neighbors: Best Accuracy <span style=\"font-weight: bold\">(</span>CV<span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9275</span> | Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9600</span> | Best Params = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'n_neighbors'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'weights'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'distance'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "K-Nearest Neighbors: Best Accuracy \u001b[1m(\u001b[0mCV\u001b[1m)\u001b[0m = \u001b[1;36m0.9275\u001b[0m | Test Accuracy = \u001b[1;36m0.9600\u001b[0m | Best Params = \u001b[1m{\u001b[0m\u001b[32m'n_neighbors'\u001b[0m: \u001b[1;36m5\u001b[0m, \n",
       "\u001b[32m'weights'\u001b[0m: \u001b[32m'distance'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 K-Nearest Neighbors Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 K-Nearest Neighbors Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.97\u001b[0m        \u001b[1;36m58\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m        \u001b[1;36m42\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.96\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.96\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.96\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Neural Network: Best Accuracy <span style=\"font-weight: bold\">(</span>CV<span style=\"font-weight: bold\">)</span> = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9250</span> | Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9500</span> | Best Params = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'activation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'relu'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'alpha'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0001</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_layer_sizes'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"font-weight: bold\">)}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Neural Network: Best Accuracy \u001b[1m(\u001b[0mCV\u001b[1m)\u001b[0m = \u001b[1;36m0.9250\u001b[0m | Test Accuracy = \u001b[1;36m0.9500\u001b[0m | Best Params = \u001b[1m{\u001b[0m\u001b[32m'activation'\u001b[0m: \u001b[32m'relu'\u001b[0m, \n",
       "\u001b[32m'alpha'\u001b[0m: \u001b[1;36m0.0001\u001b[0m, \u001b[32m'hidden_layer_sizes'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m50\u001b[0m, \u001b[1;36m50\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📋 Neural Network Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.97</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.93</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.94</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.95</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📋 Neural Network Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.97\u001b[0m      \u001b[1;36m0.96\u001b[0m        \u001b[1;36m58\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.93\u001b[0m      \u001b[1;36m0.94\u001b[0m        \u001b[1;36m42\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.95\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m      \u001b[1;36m0.95\u001b[0m       \u001b[1;36m100\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Best Model: Random Forest with Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9900</span> and Test Accuracy = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Best Model: Random Forest with Accuracy = \u001b[1;36m0.9900\u001b[0m and Test Accuracy = \u001b[1;36m0.9500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📄 Best Parameters saved in <span style=\"color: #008000; text-decoration-color: #008000\">'best_model_params.json'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📄 Best Parameters saved in \u001b[32m'best_model_params.json'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📊 Model Evaluation on Test Set:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📊 Model Evaluation on Test Set:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Accuracy: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9900</span> | 🎯 Precision: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9902</span> | 🔄 Recall: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9900</span> | 🏆 F1 Score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9900</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Accuracy: \u001b[1;36m0.9900\u001b[0m | 🎯 Precision: \u001b[1;36m0.9902\u001b[0m | 🔄 Recall: \u001b[1;36m0.9900\u001b[0m | 🏆 F1 Score: \u001b[1;36m0.9900\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model training complete. Best model saved.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model training complete. Best model saved.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No new data found. Model remains unchanged.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No new data found. Model remains unchanged.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports \n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
    "import json\n",
    "from scipy.sparse import hstack\n",
    "from rich import print\n",
    "NEW_DATA_FILE = \"new_data.csv\"  # New data for retraining, Am using a file but i take it if it could be connected to a warehous with inflowing data that would be best\n",
    "\n",
    "\n",
    "# func to load for me data\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File {file_path} not found.\")\n",
    "            return None\n",
    "        df = pd.read_csv(file_path, usecols=[\n",
    "                                        \"HH Income + Production/Day (USD)\",  # numeric\n",
    "                                        \"most_recommend_rtv_program\",  # categorical\n",
    "                                        \"least_recommend_rtv_program\",  # categorical\n",
    "                                        \"most_recommend_rtv_program_reason\",  # string\n",
    "                                        \"least_recommend_rtv_program_reason\"  # string\n",
    "                                        ])\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"File {file_path} is empty.\")\n",
    "        return None\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error parsing file {file_path}.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Func to  Clean Data\n",
    "def preprocess_data(df, training=True):\n",
    "    \"\"\"\n",
    "    Preprocess the data by imputing missing values, encoding categorical variables,\n",
    "    scaling numerical features, and extracting text features using TF-IDF.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing the features.\n",
    "    training (bool): Flag indicating whether the function is being used for training or not.\n",
    "\n",
    "    Returns:\n",
    "    X_final (pd.DataFrame): The preprocessed feature dataframe.\n",
    "    y (pd.Series): The target variable.\n",
    "    preprocessor (ColumnTransformer): The preprocessor object for numerical and categorical data.\n",
    "    vectorizer (TfidfVectorizer): The vectorizer object for text data.\n",
    "    \"\"\"\n",
    "    # Define target\n",
    "    df['risk_target'] = (df['HH Income + Production/Day (USD)'] < 2).astype(int)\n",
    "\n",
    "    # Separate features & target\n",
    "    X = df.drop(columns=['risk_target'])\n",
    "    y = df['risk_target']\n",
    "\n",
    "    # Identify categorical, numerical, and text columns\n",
    "    num_cols = ['HH Income + Production/Day (USD)']\n",
    "    cat_cols = ['most_recommend_rtv_program', 'least_recommend_rtv_program']\n",
    "    text_cols = ['most_recommend_rtv_program_reason', 'least_recommend_rtv_program_reason']\n",
    "\n",
    "    # Fill missing values\n",
    "    num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "    # Encoding & Scaling\n",
    "    onehot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Text Feature Extraction\n",
    "    vectorizer = TfidfVectorizer(max_features=100)\n",
    "\n",
    "    # Pipeline for transformations\n",
    "    num_pipeline = Pipeline([(\"imputer\", num_imputer), (\"scaler\", scaler)])\n",
    "    cat_pipeline = Pipeline([(\"imputer\", cat_imputer), (\"encoder\", onehot_encoder)])\n",
    "\n",
    "    # Apply transformations\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_cols),\n",
    "        (\"cat\", cat_pipeline, cat_cols)\n",
    "    ])\n",
    "\n",
    "    # Transform data\n",
    "    X_processed = preprocessor.fit_transform(X) if training else preprocessor.transform(X)\n",
    "\n",
    "    # Process text features\n",
    "    text_features = vectorizer.fit_transform(X[text_cols].fillna(\"Unknown\").astype(str).apply(lambda row: \" \".join(row), axis=1)).toarray()\n",
    "    text_feature_names = vectorizer.get_feature_names_out()\n",
    "    text_df = pd.DataFrame(text_features, columns=text_feature_names)\n",
    "\n",
    "    # Convert transformed data to DataFrame\n",
    "    transformed_columns = preprocessor.get_feature_names_out()\n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=transformed_columns)\n",
    "\n",
    "    # Combine all features\n",
    "    X_final = pd.concat([X_processed_df, text_df], axis=1)\n",
    "\n",
    "    return X_final, y, preprocessor, vectorizer  # Return transformations for future use\n",
    "\n",
    "\n",
    "\n",
    "# Func to Train Models\n",
    "\n",
    "def train_and_select_best_model(X_train, y_train, X_test, y_test):\n",
    "    param_grids = {\n",
    "        \"Random Forest\": {\n",
    "            \"model\": RandomForestClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [50, 100, 200],\n",
    "                \"max_depth\": [None, 10, 20],\n",
    "                \"min_samples_split\": [2, 5],\n",
    "                \"min_samples_leaf\": [1, 2]\n",
    "            }\n",
    "        },\n",
    "        \"Logistic Regression\": {\n",
    "            \"model\": LogisticRegression(max_iter=500),\n",
    "            \"params\": {\n",
    "                \"C\": [0.1, 1, 10],\n",
    "                \"solver\": [\"liblinear\", \"lbfgs\"]\n",
    "            }\n",
    "        },\n",
    "        \"Gradient Boosting\": {\n",
    "            \"model\": GradientBoostingClassifier(random_state=42),\n",
    "            \"params\": {\n",
    "                \"n_estimators\": [50, 100, 200],\n",
    "                \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "                \"max_depth\": [3, 5, 10]\n",
    "            }\n",
    "        },\n",
    "        \"Support Vector Machine\": {\n",
    "            \"model\": SVC(),\n",
    "            \"params\": {\n",
    "                \"C\": [0.1, 1, 10],\n",
    "                \"kernel\": [\"linear\", \"rbf\"]\n",
    "            }\n",
    "        },\n",
    "        \"K-Nearest Neighbors\": {\n",
    "            \"model\": KNeighborsClassifier(),\n",
    "            \"params\": {\n",
    "                \"n_neighbors\": [3, 5, 7],\n",
    "                \"weights\": [\"uniform\", \"distance\"]\n",
    "            }\n",
    "        },\n",
    "        \"Neural Network\": {\n",
    "            \"model\": MLPClassifier(max_iter=500),\n",
    "            \"params\": {\n",
    "                \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "                \"activation\": [\"relu\", \"tanh\"],\n",
    "                \"alpha\": [0.0001, 0.001]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_name = \"\"\n",
    "    best_params = {}\n",
    "\n",
    "    for name, config in param_grids.items():\n",
    "        model = config[\"model\"]\n",
    "        params = config[\"params\"]\n",
    "\n",
    "        grid_search = GridSearchCV(model, params, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        model_best_params = grid_search.best_params_\n",
    "        best_model_cv = grid_search.best_estimator_\n",
    "        best_score_cv = grid_search.best_score_\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        test_score = best_model_cv.score(X_test, y_test)\n",
    "\n",
    "        print(f\"{name}: Best Accuracy (CV) = {best_score_cv:.4f} | Test Accuracy = {test_score:.4f} | Best Params = {model_best_params}\")\n",
    "        # testing each model with classification report\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        print(f\"\\n📋 {name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "        if test_score > best_score:\n",
    "            best_score = test_score\n",
    "            best_model = best_model_cv\n",
    "            best_name = name\n",
    "            best_params = model_best_params\n",
    "\n",
    "    # Save best model parameters to JSON file\n",
    "    with open(\"best_model_params.json\", \"w\") as f:\n",
    "        json.dump({\"model\": best_name, \"accuracy\": best_score, \"params\": best_params}, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Best Model: {best_name} with Accuracy = {best_score:.4f} and Test Accuracy = {test_score:.4f}\")\n",
    "    print(f\"📄 Best Parameters saved in 'best_model_params.json'\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# func to Evaluate Models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)  # Predict on the test set\n",
    "\n",
    "    print(\"📊 Model Evaluation on Test Set:\")\n",
    "    print(f\"✅ Accuracy: {accuracy_score(y_test, y_pred):.4f} | 🎯 Precision: {precision_score(y_test, y_pred, average='weighted'):.4f} | 🔄 Recall: {recall_score(y_test, y_pred, average='weighted'):.4f} | 🏆 F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Func to Automate Retraining\n",
    "def retrain_if_new_data():\n",
    "    if os.path.exists(NEW_DATA_FILE):\n",
    "        print(\"New data found. Retraining model...\")\n",
    "\n",
    "        new_df = load_data(NEW_DATA_FILE)\n",
    "        if new_df is None:\n",
    "            print(\"New Data file is None. Check Data File\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"New Data file is Found. Check Data File\")\n",
    "            X_new, y_new, _, _ = preprocess_data(new_df, training=False)\n",
    "\n",
    "            # Load saved model\n",
    "            model = joblib.load(MODEL_FILE)\n",
    "\n",
    "            # Retrain model\n",
    "            model.fit(X_new, y_new)\n",
    "\n",
    "            # Save updated model\n",
    "            joblib.dump(model, MODEL_FILE)\n",
    "            print(\"Model retrained and updated.\")\n",
    "\n",
    "            # Remove new data file after training\n",
    "            os.remove(NEW_DATA_FILE)\n",
    "    else:\n",
    "        print(\"No new data found. Model remains unchanged.\")\n",
    "\n",
    "\n",
    "# Func to Load, Transform Data before making predicitons on data       \n",
    "\n",
    "def load_and_predict(X_new, text_column):\n",
    "   # Load the preprocessor (for numerical & categorical data)\n",
    "    preprocessor = joblib.load(\"preprocessor.pkl\")\n",
    "    X_transformed = preprocessor.transform(X_new)\n",
    "\n",
    "    # Load the vectorizer (for text features)\n",
    "    vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "    \n",
    "    # Combine text columns as done during training\n",
    "    text_series = text_column.fillna(\"Unknown\").astype(str).apply(lambda row: \" \".join(row), axis=1)\n",
    "    X_text_transformed = vectorizer.transform(text_series)\n",
    "\n",
    "    # Combine both numerical & text features\n",
    "    from scipy.sparse import hstack\n",
    "    X_final = hstack([X_transformed, X_text_transformed])\n",
    "    \n",
    "    # Get the feature names from the preprocessor and vectorizer\n",
    "    pre_cols = preprocessor.get_feature_names_out()\n",
    "    vec_cols = vectorizer.get_feature_names_out()\n",
    "    combined_cols = np.concatenate([pre_cols, vec_cols])\n",
    "    \n",
    "    # Convert the combined sparse matrix to a dense DataFrame with proper column names\n",
    "    X_final_df = pd.DataFrame(X_final.todense(), columns=combined_cols)\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = joblib.load(\"best_model.pkl\")\n",
    "    \n",
    "    # Make predictions using a DataFrame with valid feature names\n",
    "    predictions = model.predict(X_final_df)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# To map the printed predictions to human readable format\n",
    "def map_predictions(predictions):\n",
    "    mapping = {0: \"Not at risk\", 1: \"At risk\"}\n",
    "    mapped_predictions = [mapping[pred] for pred in predictions]\n",
    "\n",
    "    print(mapped_predictions)\n",
    "\n",
    "\n",
    "\n",
    "# My Main Function with entire flow logic\n",
    "def main():\n",
    "    \n",
    "    # Global Variables for file paths\n",
    "    DATA_FILE = r\"C:\\Users\\M D\\Desktop\\HRTV test\\interview_dataset.csv\"  # Main dataset\n",
    "    MODEL_FILE = \"best_model.pkl\" # Trained model file\n",
    "    PREPROCESSOR_FILE =\"preprocessor.pkl\" # Preprocessor file for data transformation\n",
    "    VECTORIZER_FILE = \"vectorizer.pkl\" # Text vectorizer file\n",
    "\n",
    "    \n",
    "    # Load data into memory\n",
    "    df = load_data(DATA_FILE)\n",
    "    if df is None:\n",
    "        print(\"Data Frame is None. Check Dataframe\")\n",
    "        exit()  # Stop execution if no data is found\n",
    "    else:\n",
    "        # Preprocess data\n",
    "        X, y, preprocessor, vectorizer = preprocess_data(df)\n",
    "        \n",
    "        # Split into training and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True , stratify=y)\n",
    "        \n",
    "        # Train and select the best model\n",
    "        best_model = train_and_select_best_model(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # Evaluate model\n",
    "        evaluate_model(best_model, X_test, y_test)\n",
    "\n",
    "        # Save best model & preprocessors\n",
    "        joblib.dump(best_model, MODEL_FILE)\n",
    "        joblib.dump(preprocessor, PREPROCESSOR_FILE)\n",
    "        joblib.dump(vectorizer, VECTORIZER_FILE)\n",
    "        print(\"Model training complete. Best model saved.\")\n",
    "        \n",
    "        # Retrain model if new data is available\n",
    "        retrain_if_new_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'At risk'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Not at risk'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'At risk'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'At risk'\u001b[0m, \u001b[32m'Not at risk'\u001b[0m, \u001b[32m'At risk'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# my small tests one unseen made up data if the model is working\n",
    "\n",
    "X_new = pd.DataFrame({\n",
    "    'HH Income + Production/Day (USD)': [1.5, 3.2, 0.8],  # Numerical data\n",
    "    'most_recommend_rtv_program': [1, 3, 'food security'],  # Categorical data\n",
    "    'least_recommend_rtv_program': [1, 99, 'active water'],  # Categorical data\n",
    "    'most_recommend_rtv_program_reason': ['low', 'Interesting characters', 'Good reviews'],  # Text data\n",
    "    'least_recommend_rtv_program_reason': ['Boring', 'Poor storyline', 'Too slow']  # Text data\n",
    "})\n",
    "\n",
    "# Ensure that both X_new and text_column have the same number of rows\n",
    "X_transformed = X_new[['HH Income + Production/Day (USD)', 'most_recommend_rtv_program', 'least_recommend_rtv_program']]\n",
    "text_column = X_new[['most_recommend_rtv_program_reason', 'least_recommend_rtv_program_reason']]\n",
    "\n",
    "# Test the prediction function with this new data\n",
    "predictions = load_and_predict(X_transformed, text_column)\n",
    "\n",
    "# Map the predictions to human-readable format\n",
    "map_predictions(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
